{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c2cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5217c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_datasets, get_dataloaders\n",
    "from random_texts import CLIPZeroShotClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6361c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59b49f865214062b4d5cbd962229a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "15\n",
      "21\n",
      "51\n",
      "52\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "datasets, classnames = get_datasets(fraction=1e-3)\n",
    "for name, dataset in datasets.items():\n",
    "    print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2189383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345/345 [00:23<00:00, 14.48it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_model = CLIPZeroShotClassifier(classnames)\n",
    "dataloaders = get_dataloaders(datasets, baseline_model.preprocess, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module) -> dict[str, float]:\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    with torch.inference_mode():\n",
    "        for name, dataloader in dataloaders.items():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch in tqdm(dataloader, desc=f\"Evaluating {name}\"):\n",
    "                images = batch[\"image\"]\n",
    "                labels = batch[\"label\"]\n",
    "                logits = model(images)\n",
    "                correct += (logits.argmax(dim=-1) == labels).float().sum()\n",
    "                total += len(labels)\n",
    "            results[name] = correct / total\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda08e19",
   "metadata": {},
   "source": [
    "## Zero-shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393805d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ID: 100%|██████████| 1/1 [00:07<00:00,  7.69s/it]\n",
      "Evaluating OOD_infograph: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Evaluating OOD_painting: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Evaluating OOD_quickdraw: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "Evaluating OOD_real: 100%|██████████| 1/1 [00:03<00:00,  3.06s/it]\n",
      "Evaluating OOD_clipart: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': tensor(0.8417),\n",
      " 'OOD_clipart': tensor(0.6500),\n",
      " 'OOD_infograph': tensor(0.4000),\n",
      " 'OOD_painting': tensor(0.7619),\n",
      " 'OOD_quickdraw': tensor(0.1373),\n",
      " 'OOD_real': tensor(0.8269)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_results = evaluate(baseline_model)\n",
    "pprint(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa164074",
   "metadata": {},
   "source": [
    "## Full fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca55f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345/345 [00:25<00:00, 13.67it/s]\n"
     ]
    }
   ],
   "source": [
    "ft_model = CLIPZeroShotClassifier(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aedef8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning: 100%|██████████| 1/1 [00:25<00:00, 25.70s/it, loss=0.6562]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(ft_model.parameters(), lr=3e-5, weight_decay=0.1)\n",
    "total_steps = len(dataloaders[\"ID\"])\n",
    "warmup_steps = min(500, total_steps // 2)\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.1,\n",
    "    total_iters=warmup_steps,\n",
    ")\n",
    "cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_steps - warmup_steps,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "    milestones=[warmup_steps],\n",
    ")\n",
    "pbar = tqdm(dataloaders[\"ID\"], desc=\"Fine-tuning\")\n",
    "for batch in pbar:\n",
    "    images = batch[\"image\"]\n",
    "    labels = batch[\"label\"]\n",
    "    logits = ft_model(images)\n",
    "    loss = nn.functional.cross_entropy(logits, labels)\n",
    "    pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eabc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ID: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n",
      "Evaluating OOD_infograph: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "Evaluating OOD_painting: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Evaluating OOD_quickdraw: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "Evaluating OOD_real: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "Evaluating OOD_clipart: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': tensor(0.9083),\n",
      " 'OOD_clipart': tensor(0.6500),\n",
      " 'OOD_infograph': tensor(0.4000),\n",
      " 'OOD_painting': tensor(0.7619),\n",
      " 'OOD_quickdraw': tensor(0.1373),\n",
      " 'OOD_real': tensor(0.8269)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ft_results = evaluate(ft_model)\n",
    "pprint(ft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221a371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
