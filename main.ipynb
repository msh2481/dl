{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c2cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5217c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_datasets, get_dataloaders\n",
    "from random_texts import CLIPZeroShotClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6361c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd11841976b94fea9c809805eb46742a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "15\n",
      "21\n",
      "51\n",
      "52\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "datasets, classnames = get_datasets(fraction=1e-3)\n",
    "for name, dataset in datasets.items():\n",
    "    print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2189383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot classifier: 100%|██████████| 345/345 [00:29<00:00, 11.62it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_model = CLIPZeroShotClassifier(classnames)\n",
    "dataloaders = get_dataloaders(datasets, baseline_model.preprocess, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ec1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module) -> dict[str, float]:\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    with torch.inference_mode():\n",
    "        for name, dataloader in dataloaders.items():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for batch in tqdm(dataloader, desc=f\"Evaluating {name}\"):\n",
    "                images = batch[\"image\"]\n",
    "                labels = batch[\"label\"]\n",
    "                logits = model(images)\n",
    "                correct += (logits.argmax(dim=-1) == labels).float().sum()\n",
    "                total += len(labels)\n",
    "            results[name] = correct / total\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda08e19",
   "metadata": {},
   "source": [
    "## Zero-shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393805d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ID: 100%|██████████| 1/1 [00:07<00:00,  7.69s/it]\n",
      "Evaluating OOD_infograph: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Evaluating OOD_painting: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "Evaluating OOD_quickdraw: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "Evaluating OOD_real: 100%|██████████| 1/1 [00:03<00:00,  3.06s/it]\n",
      "Evaluating OOD_clipart: 100%|██████████| 1/1 [00:01<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': tensor(0.8417),\n",
      " 'OOD_clipart': tensor(0.6500),\n",
      " 'OOD_infograph': tensor(0.4000),\n",
      " 'OOD_painting': tensor(0.7619),\n",
      " 'OOD_quickdraw': tensor(0.1373),\n",
      " 'OOD_real': tensor(0.8269)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_results = evaluate(baseline_model)\n",
    "pprint(baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa164074",
   "metadata": {},
   "source": [
    "## Full fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca55f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 345/345 [00:25<00:00, 13.67it/s]\n"
     ]
    }
   ],
   "source": [
    "ft_model = CLIPZeroShotClassifier(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aedef8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning: 100%|██████████| 1/1 [00:25<00:00, 25.70s/it, loss=0.6562]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(ft_model.parameters(), lr=3e-5, weight_decay=0.1)\n",
    "total_steps = len(dataloaders[\"ID\"])\n",
    "warmup_steps = min(500, total_steps // 2)\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.1,\n",
    "    total_iters=warmup_steps,\n",
    ")\n",
    "cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_steps - warmup_steps,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "    milestones=[warmup_steps],\n",
    ")\n",
    "pbar = tqdm(dataloaders[\"ID\"], desc=\"Fine-tuning\")\n",
    "for batch in pbar:\n",
    "    images = batch[\"image\"]\n",
    "    labels = batch[\"label\"]\n",
    "    logits = ft_model(images)\n",
    "    loss = nn.functional.cross_entropy(logits, labels)\n",
    "    pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ft_model.pth\", \"wb\") as f:\n",
    "    torch.save(ft_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eabc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ID: 100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n",
      "Evaluating OOD_infograph: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "Evaluating OOD_painting: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Evaluating OOD_quickdraw: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "Evaluating OOD_real: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "Evaluating OOD_clipart: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': tensor(0.9083),\n",
      " 'OOD_clipart': tensor(0.6500),\n",
      " 'OOD_infograph': tensor(0.4000),\n",
      " 'OOD_painting': tensor(0.7619),\n",
      " 'OOD_quickdraw': tensor(0.1373),\n",
      " 'OOD_real': tensor(0.8269)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ft_results = evaluate(ft_model)\n",
    "pprint(ft_results)\n",
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54f0e1",
   "metadata": {},
   "source": [
    "## Lipsum-FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8221a371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot classifier: 100%|██████████| 345/345 [00:23<00:00, 14.88it/s]\n"
     ]
    }
   ],
   "source": [
    "lipsum_model = CLIPZeroShotClassifier(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c842b73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙏🏼 lgbti wr ➤ shedlight care surro\n",
      "kamal ctive tob ii mags proj acea emed \n",
      "buzz cur bredyap straight nigel peregravail \n",
      "leash memory mach🇷🇺 happens domestdrome daz\n",
      "pkwy axelkon scary fault dana minus ía \n",
      "pion issaseaworld hipsters accommodate processors grumpy lizards \n",
      "gzchand adic wec caterpillar charlesdren; \n",
      "reminding poppyyash snazzy maz pressing rahuundocumented \n",
      "speed sevxalbums umni enthreventoss \n",
      "photobomb millennium rift ruewifey icelandic iciff \n",
      "machinefiftycoke�satishomerdebates howe \n",
      "alliancetins edged nation pilooklahoma leur partner\n",
      "ceiling dempsey standalone jdm sightings anchored caliber dder \n",
      "▪pent ⭐⭐earts wahgenerates tered saver \n",
      "frampton bookofbettersickest routines mast⁦⁦@ atoday \n",
      "berto saffron ffler sorrows miro 🤩bingashok \n"
     ]
    }
   ],
   "source": [
    "from clip.clip import _tokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sample_random_tokens(n: int, L: int = 8):\n",
    "    V = len(_tokenizer.encoder)\n",
    "    return [\n",
    "        \"\".join(_tokenizer.decode(np.random.randint(0, V, size=L))) for _ in range(n)\n",
    "    ]\n",
    "\n",
    "\n",
    "print(*sample_random_tokens(16), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b38c2403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning: 100%|██████████| 1/1 [01:35<00:00, 95.54s/it, ce_loss=0.6431, gap_loss=0.0000]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(lipsum_model.parameters(), lr=3e-5, weight_decay=0.1)\n",
    "total_steps = len(dataloaders[\"ID\"])\n",
    "warmup_steps = min(500, total_steps // 2)\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.1,\n",
    "    total_iters=warmup_steps,\n",
    ")\n",
    "cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_steps - warmup_steps,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "    milestones=[warmup_steps],\n",
    ")\n",
    "lambda_lipsum = 0.1\n",
    "pbar = tqdm(dataloaders[\"ID\"], desc=\"Fine-tuning\")\n",
    "for batch in pbar:\n",
    "    images = batch[\"image\"]\n",
    "    labels = batch[\"label\"]\n",
    "    texts = sample_random_tokens(len(images))\n",
    "    logits = lipsum_model(images)\n",
    "    cur_energy = lipsum_model.get_energy(images, texts)\n",
    "    with torch.no_grad():\n",
    "        old_energy = baseline_model.get_energy(images, texts)\n",
    "    ce_loss = nn.functional.cross_entropy(logits, labels)\n",
    "    gap_loss = nn.functional.mse_loss(cur_energy, old_energy)\n",
    "    loss = ce_loss + lambda_lipsum * gap_loss\n",
    "    pbar.set_postfix(ce_loss=f\"{ce_loss.item():.4f}\", gap_loss=f\"{gap_loss.item():.4f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bbf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lipsum_model.pth\", \"wb\") as f:\n",
    "    torch.save(lipsum_model.state_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
